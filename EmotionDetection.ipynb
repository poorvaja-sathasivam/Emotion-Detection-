{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfq1uRCyQ2xrV80TMSXe9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poorvaja-sathasivam/Emotion-Detection-/blob/main/EmotionDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az4m_5tJ4cBN"
      },
      "outputs": [],
      "source": [
        "# 1. Importing all the necessary libraries. \n",
        "import tensorflow as tf \n",
        "import os \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import cv2 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "25hZYkDs9G6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q Data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LlhcIS6_eLf",
        "outputId": "606718fa-9447-4b94-96fe-31baff397dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open Data.zip, Data.zip.zip or Data.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "# Getting the images for training \n",
        "imgArr = cv2.imread(\"Data/Training/1/Training_3908.jpg\")"
      ],
      "metadata": {
        "id": "x6Y5iMJ55KHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking size of the image \n",
        "imgArr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "zbo0-Ic05LB2",
        "outputId": "580bfa04-5d7f-4f34-acd2-098322af94de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b5eaee9119fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking size of the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimgArr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the image\n",
        "plt.imshow(imgArr)"
      ],
      "metadata": {
        "id": "BZP4Xr7K5QB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a data directory \n",
        "DirectoryOfData = \"Data/Training/\" "
      ],
      "metadata": {
        "id": "THPNHJMF_tF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of classes which are named the same as the folder\n",
        "Classes = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]"
      ],
      "metadata": {
        "id": "ji1IJC5K_vxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading all the images in the folder \n",
        "for Category in Classes:\n",
        "    path = os.path.join(DirectoryOfData, Category)\n",
        "    for img in os.listdir(path):\n",
        "        imgArr = cv2.imread(os.path.join(path,img))\n",
        "#         imgtorgb = cv2.cvtColor(imgArr,cv2.COLOR_GRAY2RGB)\n",
        "        plt.imshow(cv2.cvtColor(imgArr, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "        break \n",
        "    break"
      ],
      "metadata": {
        "id": "WLj72J6-_yuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the size of the image \n",
        "# As ImageNet has a size of 224 x 224, the size is set as 224 \n",
        "sizeOfImage = 224 \n",
        "newArr = cv2.resize(imgArr,(sizeOfImage,sizeOfImage))\n",
        "plt.imshow(cv2.cvtColor(newArr,cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n",
        "# Therefore, the size will change from 48x48 to 224x224 "
      ],
      "metadata": {
        "id": "n8iRO6Rh_013"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the size has changed \n",
        "newArr.shape"
      ],
      "metadata": {
        "id": "B9AAYCNC_4rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading all the images and converting them to an Array \n",
        "trainingSet = []\n",
        "\n",
        "# Function to create the training data \n",
        "def createTrainingSet():\n",
        "    for Category in Classes:\n",
        "        path = os.path.join(DirectoryOfData, Category)\n",
        "        numOfClass = Classes.index(Category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                imgArr = cv2.imread(os.path.join(path,img))\n",
        "                newArr = cv2.resize(imgArr, (sizeOfImage, sizeOfImage))\n",
        "                trainingSet.append([newArr,numOfClass])\n",
        "            except Expection as e:\n",
        "                pass"
      ],
      "metadata": {
        "id": "VdA0V5nb_6rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the function \n",
        "createTrainingSet()"
      ],
      "metadata": {
        "id": "qp5Kt7j-_9vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of images that has read by the function \n",
        "print(len(trainingSet))"
      ],
      "metadata": {
        "id": "12l9APXVABi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid making the model learn the sequence, shuffling of the data is used \n",
        "import random \n",
        "random.shuffle(trainingSet)\n",
        "# This helps the model to be more dynamic and robust "
      ],
      "metadata": {
        "id": "aKmAQHTUAHrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A and B are variables used for features and label  \n",
        "A = [] \n",
        "B = []\n",
        "\n",
        "for feature, label, in trainingSet:\n",
        "    A.append(feature)\n",
        "    B.append(label)\n",
        "\n",
        "# Converting to 4 dimensions. \n",
        "A = np.array(A).reshape(-1,sizeOfImage, sizeOfImage, 3)\n",
        "\n",
        "# Checking the shape \n",
        "A.shape"
      ],
      "metadata": {
        "id": "NGY2AYxZALF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Normalising the data where 255 stands for black(maximum) and 0 stands for white(minimum)\n",
        "# A = A/255.0; "
      ],
      "metadata": {
        "id": "XsRhDj3IANOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the type of B \n",
        "type(B)"
      ],
      "metadata": {
        "id": "fdsWuN4NATBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to an array \n",
        "BB = np.array(B) \n",
        "# Checking the shape \n",
        "BB.shape"
      ],
      "metadata": {
        "id": "1eH4dT1hA9PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "nFgv4SSBBD08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-trained model \n",
        "model = tf.keras.applications.MobileNetV2()"
      ],
      "metadata": {
        "id": "-sB4lT06BHoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3lHKCplzBJpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model is trained for 1000 classes which is showed as predictions(Dense) : (None, 1000) ==> therefore performing transfer learning \n",
        "baseInput = model.layers[0].input"
      ],
      "metadata": {
        "id": "lsgMBn5HBMsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting only 7 classes \n",
        "baseOutput = model.layers[-2].output"
      ],
      "metadata": {
        "id": "OzCLEQQKBPlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseOutput"
      ],
      "metadata": {
        "id": "9PHmoqhRBRuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating a new layer after the global average pooling layer (None, 1280)\n",
        "finOutput = layers.Dense(128)(baseOutput)\n",
        "# 2. Creating the activation function \n",
        "fOutput = layers.Activation('relu')(finOutput)\n",
        "# 3. Creating another layer \n",
        "finOutput = layers.Dense(64)(finOutput)\n",
        "# 4. Creating the activation function \n",
        "fOutput = layers.Activation('relu')(finOutput)\n",
        "# Since the classes are 7, it will be reduced from 1000 to 7 \n",
        "finOutput = layers.Dense(7,activation = 'softmax')(finOutput)"
      ],
      "metadata": {
        "id": "FHwg-8u9BTvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finOutput"
      ],
      "metadata": {
        "id": "xqD0gq6iBWak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel = keras.Model(inputs = baseInput, outputs = finOutput)"
      ],
      "metadata": {
        "id": "xFiKs-S4BYaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel.summary()"
      ],
      "metadata": {
        "id": "z8Z4WOIXBaWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"adam\", metrics =[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ES0sySG-BcBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel.fit(A,BB, epochs = 1)"
      ],
      "metadata": {
        "id": "G8U7SZMHYIG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel.save('Model.h5')"
      ],
      "metadata": {
        "id": "NVdUdRQCYJW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel = tf.keras.models.load_model(\"Model.h5\")"
      ],
      "metadata": {
        "id": "xGmExcjVYOmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel.evaluate "
      ],
      "metadata": {
        "id": "U2-W7X-vYWJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = cv2.imread(\"girl.jpg\")"
      ],
      "metadata": {
        "id": "pGMrFIKwYnqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new.shape"
      ],
      "metadata": {
        "id": "667UnDbWZJy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.cvtColor(new,cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "R4g3SCX3ZOGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "UUBMHHhXZj8R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}